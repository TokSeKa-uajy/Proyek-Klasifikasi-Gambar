# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZJhMG8v3LiCufpPF2nFX6rT_bltgDliU

# Proyek Klasifikasi Gambar: Jenis Beras (https://www.kaggle.com/datasets/muratkokludataset/rice-image-dataset)
####Abstrak:
- **Nama:** Tok Se Ka
- **Email:** sekacoding@gmail.com
- **ID Dicoding:** MC185D5Y2370

ini berisi foto dari 5 jenis beras yang memiliki jumlah foto yang seimbang dan memiliki total 75000 file gambar yang tersebar masing masing 15000 foto per kelas.

### Mengimport library yang diperlukan
"""

# Commented out IPython magic to ensure Python compatibility.
# Library yang sering digunakan
import os, shutil
import zipfile
import random
from random import sample
import shutil
from shutil import copyfile
import pathlib
from pathlib import Path
import numpy as np
import pandas as pd
from tqdm.notebook import tqdm as tq

# Mengimpor libraries untuk visualisasi
# %matplotlib inline
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.image import imread

# Libraries untuk pemrosesan data gambar
import cv2
from PIL import Image
import skimage
from skimage import io
from skimage.transform import resize
from skimage.transform import rotate, AffineTransform, warp
from skimage import img_as_ubyte
from skimage.exposure import adjust_gamma
from skimage.util import random_noise

# Libraries untuk pembangunan model
import keras
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
import tensorflow as tf
from tensorflow.keras import Model, layers
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
from tensorflow.keras.optimizers import Adam, RMSprop, SGD
from tensorflow.keras.layers import InputLayer, Conv2D, SeparableConv2D, MaxPooling2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.applications import MobileNet
from tensorflow.keras.applications.densenet import DenseNet121
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau

import os
import shutil

from sklearn.utils.class_weight import compute_class_weight

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

# Import module yang disediakan google colab untuk kebutuhan upload file

from google.colab import files
files.upload()

"""### Mengimport folder kaggle dan langsung unzip di colab."""

# 1. Buat folder .kaggle
!mkdir -p ~/.kaggle
# 2. Pindahkan file kaggle.json ke folder .kaggle
!cp kaggle.json ~/.kaggle/
# 3. Ubah permission-nya agar hanya bisa diakses sendiri
!chmod 600 ~/.kaggle/kaggle.json
# 4. Install dan gunakan kaggle CLI
!pip install -q kaggle
# 5. Download dataset dari Kaggle
!kaggle datasets download -d muratkokludataset/rice-image-dataset
# 6. Unzip dataset-nya
!unzip rice-image-dataset.zip

"""### Menghapus txt dan ipynb_checkpoints yang tidak berhubungan dengan dataset."""

!rm -r Rice_Image_Dataset/.ipynb_checkpoints #checkpointnya muncul didalam dataset
!rm -r Rice_Image_Dataset/Rice_Citation_Request.txt #checkpointnya muncul didalam dataset

"""### Membuat kamus yang menyimpan gambar untuk setiap kelas dalam data dan menampilkan secara acak 5 gambar di bawah setiap kelas dari data latih"""

# Membuat kamus yang menyimpan gambar untuk setiap kelas dalam data
rice_image = {}

# Tentukan path sumber train
path = "Rice_Image_Dataset/"

for i in os.listdir(path):
    rice_image[i] = os.listdir(os.path.join(path, i))

# Menampilkan secara acak 5 gambar di bawah setiap kelas dari data latih
fig, axs = plt.subplots(len(rice_image.keys()), 5, figsize=(15, 15))

for i, class_name in enumerate(os.listdir(path)):
    images = np.random.choice(rice_image[class_name], 5, replace=False)

    for j, image_name in enumerate(images):
        img_path = os.path.join(path, class_name, image_name)
        img = Image.open(img_path).convert("L")  # Konversi menjadi skala keabuan
        axs[i, j].imshow(img, cmap='gray')
        axs[i, j].set(xlabel=class_name, xticks=[], yticks=[])


fig.tight_layout()

"""### Melihat dan memberikan label untuk setiap gambar sesuai dengan folder yang ditempati, dan melakukan plot distribusi gambar untuk melihat pesebaran gambar yang telah di unduh (semuanya sama rata)."""

# Definisikan path sumber
rice_path = "Rice_Image_Dataset"

# Buat daftar yang menyimpan data untuk setiap nama file, path file, dan label dalam data
file_name = []
labels = []
full_path = []

# Dapatkan nama file gambar, path file, dan label satu per satu dengan looping, dan simpan sebagai dataframe
for path, subdirs, files in os.walk(rice_path):
    for name in files:
        full_path.append(os.path.join(path, name))
        labels.append(path.split('/')[-1])
        file_name.append(name)

distribution_train = pd.DataFrame({"path":full_path, 'file_name':file_name, "labels":labels})

# Plot distribusi gambar di setiap kelas
Label = distribution_train['labels']
plt.figure(figsize = (6,6))
sns.set_style("darkgrid")
plot_data = sns.countplot(Label)

"""### Untuk memastikan ulang, melihat kembali dan menampilkannya dalam bentuk dataframe"""

# Panggil variabel mypath yang menampung folder dataset gambar
mypath= 'Rice_Image_Dataset'

file_name = []
labels = []
full_path = []
for path, subdirs, files in os.walk(mypath):
    for name in files:
        full_path.append(os.path.join(path, name))
        labels.append(path.split('/')[-1])
        file_name.append(name)

# Memasukkan variabel yang sudah dikumpulkan pada looping di atas menjadi sebuah dataframe agar rapi
df = pd.DataFrame({"path":full_path,'file_name':file_name,"labels":labels})
# Melihat jumlah data gambar pada masing-masing label
df.groupby(['labels']).size()

"""### Memisahkan datasetmenjadi data train dan data test"""

# Variabel yang digunakan pada pemisahan data ini di mana variabel x = data path dan y = data labels

X= df['path']
y= df['labels']

# Split dataset awal menjadi data train dan test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=300)

# Menyatukan ke dalam masing-masing dataframe
df_tr = pd.DataFrame({'path':X_train,'labels':y_train,'set':'train'})
df_te = pd.DataFrame({'path':X_test,'labels':y_test,'set':'test'})

# Gabungkan DataFrame df_tr dan df_te
df_all = pd.concat([df_tr, df_te], ignore_index=True)

print('===================================================== \n')
print(df_all.groupby(['set', 'labels']).size(), '\n')
print('===================================================== \n')

# Cek sampel data
print(df_all.sample(5))

# Memanggil dataset asli yang berisi keseluruhan data gambar yang sesuai dengan labelnya
datasource_path = "chest_xray/dataset/"
# Membuat variabel Dataset, tempat menampung data yang telah dilakukan pembagian data training dan testing
dataset_path = "Dataset-Final/"

for index, row in tq(df_all.iterrows()):
    # Deteksi filepath
    file_path = row['path']
    if os.path.exists(file_path) == False:
            file_path = os.path.join(datasource_path,row['labels'],row['image'].split('.')[0])

    # Buat direktori tujuan folder
    if os.path.exists(os.path.join(dataset_path,row['set'],row['labels'])) == False:
        os.makedirs(os.path.join(dataset_path,row['set'],row['labels']))

    # Tentukan tujuan file
    destination_file_name = file_path.split('/')[-1]
    file_dest = os.path.join(dataset_path,row['set'],row['labels'],destination_file_name)

    # Salin file dari sumber ke tujuan
    if os.path.exists(file_dest) == False:
        shutil.copy2(file_path,file_dest)

# Definisikan direktori train dan test
TRAIN_DIR = "Dataset-Final/train/"
TEST_DIR = "Dataset-Final/test/"

# Ambil nama-nama kelas (folder di dalam train)
rice_classes = os.listdir(TRAIN_DIR)

# Hitung jumlah file per kelas di train dan test
print("=== TRAIN DATA ===")
for rice_class in rice_classes:
    class_dir = os.path.join(TRAIN_DIR, rice_class)
    if os.path.isdir(class_dir):
        num_images = len(os.listdir(class_dir))
        print(f"Jumlah gambar kelas {rice_class} (train): {num_images}")

print("\n=== TEST DATA ===")
for rice_class in rice_classes:
    class_dir = os.path.join(TEST_DIR, rice_class)
    if os.path.isdir(class_dir):
        num_images = len(os.listdir(class_dir))
        print(f"Jumlah gambar kelas {rice_class} (test): {num_images}")

"""### Dataset Dibagi Menjadi Train Set, Test Set dan Validation Set."""

# Buat objek ImageDataGenerator yang menormalkan gambar
datagen = ImageDataGenerator(rescale=1/255.,
                             validation_split = 0.2)
test_datagen = ImageDataGenerator(rescale=1. / 255)

train_generator = datagen.flow_from_directory(TRAIN_DIR,
                                              batch_size=32,
                                              target_size=(150,150),
                                              color_mode="grayscale",
                                              class_mode='categorical',
                                              subset='training',
                                              shuffle=True)

validation_generator = datagen.flow_from_directory(TRAIN_DIR,
                                                   batch_size=32,
                                                   target_size=(150,150),
                                                color_mode="grayscale",
                                                   class_mode='categorical',
                                                   subset='validation',
                                                   shuffle=False)

test_generator = test_datagen.flow_from_directory(TEST_DIR,
                                                  batch_size=1,
                                                  target_size=(150,150),
                                                  color_mode="grayscale",
                                                  class_mode='categorical',
                                                  shuffle=False)

print("Train steps per epoch:", train_generator.samples)
print("Validation steps per epoch:", validation_generator.samples)
print("Test samples:", test_generator.samples)

"""### Melatih Model Menggunakan Model Sequential, Conv2D, Pooling Layer
#####Model CNN dibangun menggunakan arsitektur Sequential dari Keras, yang memungkinkan penambahan layer secara berurutan dan intuitif. Model ini terdiri dari tiga blok Conv2D yang masing-masing diikuti oleh BatchNormalization dan MaxPooling, sehingga mampu mengekstraksi fitur spasial dari gambar input berukuran 150x150 piksel dalam format grayscale.

#####Setelah ekstraksi fitur, model dilanjutkan dengan beberapa fully connected layer dan Dropout untuk mencegah overfitting. Lapisan output menggunakan softmax untuk mengklasifikasikan gambar ke dalam lima kelas.

#####Model dikompilasi dengan optimizer RMSprop, fungsi loss categorical_crossentropy, dan metrik accuracy.
"""

####################### Init sequential model ##################################
model_1 = Sequential()

# ######################### Input layer with Fully Connected Layer ################################
# 1st Convolutional Block
model_1.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(150,150,1)))
model_1.add(BatchNormalization())
model_1.add(MaxPool2D((2, 2)))

# 2nd Convolutional Block
model_1.add(Conv2D(32, (4, 4),padding='same', activation='relu'))
model_1.add(BatchNormalization())
model_1.add(MaxPool2D((2, 2)))

# 3rd Convolutional Block
model_1.add(Conv2D(32, (7, 7), padding='same', activation='relu'))
model_1.add(BatchNormalization())
model_1.add(MaxPool2D((2, 2)))

# Fully Connected Layers
model_1.add(Flatten())
model_1.add(Dense(128, activation='relu'))
model_1.add(Dropout(0.5))
model_1.add(Dense(64, activation='relu'))
model_1.add(Dropout(0.3))

# Output Layer (5 kelas â†’ softmax)
model_1.add(Dense(5, activation='softmax'))

# Compile
model_1.compile(optimizer=tf.keras.optimizers.RMSprop(),
                loss='categorical_crossentropy',
                metrics=['accuracy'])

# Print arsitektur
model_1.summary()

# Bersihkan session lama (optional)
tf.keras.backend.clear_session()

"""### Menambahkan callback"""

# Callbacks
checkpoint = ModelCheckpoint(
    filepath='best_model.h5',
    monitor='val_loss',
    save_best_only=True,
    mode='min',
    verbose=1
)

early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=6,
    restore_best_weights=True,
    verbose=1
)

"""###MengaMbil label dan melakukan training model / fitting"""

# Commented out IPython magic to ensure Python compatibility.
# Ambil label class dari generator
labels = train_generator.classes

# Hitung class weights
class_weights_array = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(labels),
    y=labels
)

# Konversi ke dict
class_weights = dict(enumerate(class_weights_array))
print("Class weights:", class_weights)


# %time

# Fitting / training model
history_1 = model_1.fit(train_generator,
                        epochs=30,
                        batch_size=32,
                        validation_data=validation_generator,
                        class_weight = class_weights,
                        callbacks=[checkpoint, early_stopping])

"""###Melihat nilai akurasi dan loss dari hasil training
#####Agak tidak stabil, tetapi masih bisa di toleransi seharusnya.
"""

# Ambil nilai akurasi dan loss dari hasil training
acc = history_1.history['accuracy']
val_acc = history_1.history['val_accuracy']
loss = history_1.history['loss']
val_loss = history_1.history['val_loss']

# Epochs-nya diambil dari panjang data history
epochs = range(len(acc))

# Plot Accuracy
plt.figure()
plt.plot(epochs, acc, 'r', label='Training Accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='upper left')
plt.grid(True)
plt.show()

# Plot Loss
plt.figure()
plt.plot(epochs, loss, 'r', label='Training Loss')
plt.plot(epochs, val_loss, 'b', label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(loc='upper left')
plt.grid(True)
plt.show()

"""### Melakukan pengecekan ulang menggunakan Confusion Matrix beserta Classification Report.
#####Setelah proses pelatihan selesai, model dievaluasi kembali menggunakan confusion matrix dan classification report untuk mengetahui performa klasifikasi secara lebih detail per kelas.

#####Gambar di bawah menunjukkan bahwa mayoritas prediksi model tepat pada kelasnya masing-masing, dengan sangat sedikit kesalahan antar kelas.

#####Model memiliki performa sangat tinggi secara keseluruhan, dengan:
- Accuracy: 99.11%
- F1-Score per kelas: semuanya di atas 0.98
- Macro avg & weighted avg: juga 0.9911

#####Hal ini menunjukkan bahwa model tidak hanya unggul pada kelas mayoritas, tapi juga mampu mempertahankan performa tinggi di semua kelas secara merata.
"""

# Reset generator untuk memastikan prediksi mulai dari awal
test_generator.reset()

# Prediksi
preds_1 = model_1.predict(test_generator, verbose=0)

# Ambil index dengan probabilitas tertinggi (prediksi kelas)
y_pred = np.argmax(preds_1, axis=1)

# Ambil label asli
y_true = test_generator.classes

# Daftar nama kelas (kalau ada, ambil dari generator)
class_names = list(test_generator.class_indices.keys())  # atau ['class1', 'class2', ..., 'class5']

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
df_cm = pd.DataFrame(cm, index=[f'Actual {name}' for name in class_names],
                        columns=[f'Predicted {name}' for name in class_names])

plt.figure(figsize=(10, 7))
sns.heatmap(df_cm, annot=True, fmt="d", cmap='Blues')
plt.title("Confusion Matrix")
plt.ylabel("True Labels")
plt.xlabel("Predicted Labels")
plt.show()

# Classification Report
print("\nClassification Report:\n")
print(classification_report(y_true, y_pred, target_names=class_names, digits=4))

"""### Menyimpan model dalam bentuk savedmodel"""

save_path = 'mymodel/'
tf.saved_model.save(model_1, save_path)

"""### Menyimpan model dalam bentuk tensorflow.js"""

!tensorflowjs_converter \
  --input_format=tf_saved_model \
  mymodel \
  web_model

"""### Dalam bentuk tensorflow lite"""

converter = tf.lite.TFLiteConverter.from_saved_model('mymodel')
tflite_model = converter.convert()

tflite_model_file = pathlib.Path('model_1.tflite')
tflite_model_file.write_bytes(tflite_model)

"""### Memakai model yang telah tersimpan sebelumnya.
##### Setelah di load, lalu diambil dataset dari test generator sebagai bahan test karena belum pernah dihapal oleh model, diambil 1 pcs untuk bahan test (data ke 12345). Setelah itu ditampilkan gambar, label, serta hasilnya untuk melihat seberapa baik model ini menampilkan dan menjawab gambarnya.
"""

# Load model dari SavedModel dengan Keras 3
inference_layer = keras.layers.TFSMLayer("mymodel", call_endpoint="serving_default")

# Ambil 1 gambar dari test_generator
test_generator.reset()
x, y = test_generator[12345]  # batch 12345
image = x[0]              # ambil satu gambar
true_label = y[0]         # ambil label aslinya (one-hot)

# Inference
result = inference_layer(np.expand_dims(image, axis=0))
pred_probs = result["output_0"]
pred_class = np.argmax(pred_probs)
true_class = np.argmax(true_label)

# Mapping label ke nama kelas
class_names = list(test_generator.class_indices.keys())

# Tampilkan gambar & hasil prediksi
plt.imshow(image.squeeze(), cmap="gray")
plt.title(f"True: {class_names[true_class]} | Predicted: {class_names[pred_class]}")
plt.axis("off")
plt.show()

# Tampilkan probabilitas prediksi
print("Probabilitas prediksi:")
for i, prob in enumerate(pred_probs[0]):
    print(f"{class_names[i]}: {prob:.4f}")